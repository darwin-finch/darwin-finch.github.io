<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Finch — Local AI Coding Assistant</title>
  <meta name="description" content="Open-source AI coding assistant that runs entirely on your machine. Offline. Private. 6 model families. Apple Neural Engine acceleration. Built in Rust.">
  <meta property="og:title" content="Finch — Local AI Coding Assistant">
  <meta property="og:description" content="Offline. Private. 6 model families. ANE acceleration on Apple Silicon. Built in Rust.">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://darwin-finch.github.io">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Finch — Local AI Coding Assistant">
  <meta name="twitter:description" content="Offline. Private. 6 model families. ANE acceleration on Apple Silicon. Built in Rust.">
  <link rel="icon" href="favicon.svg" type="image/svg+xml">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;700&display=swap">
  <link rel="stylesheet" href="style.css">
</head>
<body>

<!-- CRT scanline overlay -->
<div class="crt" aria-hidden="true"></div>

<!-- ═══════════════════════════════════════════
     NAV
═══════════════════════════════════════════ -->
<nav id="nav">
  <a href="/" class="nav-logo">FINCH</a>
  <button class="nav-toggle" onclick="toggleNav()" aria-label="Menu">☰</button>
  <div class="nav-links" id="nav-links">
    <a href="#features">FEATURES</a>
    <a href="#how-it-works">HOW&nbsp;IT&nbsp;WORKS</a>
    <a href="#install">INSTALL</a>
    <a href="docs.html">DOCS</a>
    <a href="https://github.com/darwin-finch/finch" target="_blank" rel="noopener">GITHUB</a>
  </div>
</nav>

<!-- ═══════════════════════════════════════════
     HERO
═══════════════════════════════════════════ -->
<section id="hero">
  <div class="hero-inner">

    <pre class="logo-art" aria-label="FINCH">██████╗ ██╗███╗   ██╗ ██████╗██╗  ██╗
██╔════╝██║████╗  ██║██╔════╝██║  ██║
█████╗  ██║██╔██╗ ██║██║     ███████║
██╔══╝  ██║██║╚██╗██║██║     ██╔══██║
██║     ██║██║ ╚████║╚██████╗██║  ██║
╚═╝     ╚═╝╚═╝  ╚═══╝ ╚═════╝╚═╝  ╚═╝</pre>

    <p class="hero-sub">AI coding assistant · runs on your machine · works offline · learns your style</p>

    <div class="badges">
      <span>WRITTEN IN RUST</span>
      <span>WORKS OFFLINE</span>
      <span>PRIVATE BY DEFAULT</span>
      <span>OPEN SOURCE</span>
    </div>

    <!-- Animated terminal -->
    <div class="terminal" id="terminal">
      <div class="term-bar">
        <span class="dot dot-r"></span>
        <span class="dot dot-y"></span>
        <span class="dot dot-g"></span>
        <span class="term-title">zsh — finch — 80×24</span>
      </div>
      <div class="term-body">
        <div id="term-out"></div>
        <span class="term-cursor">▋</span>
      </div>
    </div>

    <div class="hero-ctas">
      <a href="#install" class="btn-primary">INSTALL NOW</a>
      <a href="https://github.com/darwin-finch/finch" class="btn-ghost" target="_blank" rel="noopener">★ VIEW ON GITHUB</a>
    </div>

  </div>
</section>

<!-- ═══════════════════════════════════════════
     THE PITCH
═══════════════════════════════════════════ -->
<section id="pitch">
  <div class="pitch-inner">
    <div class="pitch-col">
      <h2 class="pitch-label">// THE PROBLEM</h2>
      <ul class="pitch-list bad">
        <li>Constant internet connection required</li>
        <li>Every query costs API money</li>
        <li>Your code goes to the cloud</li>
        <li>No learning from your patterns</li>
        <li>Ongoing API costs for every single query</li>
      </ul>
    </div>
    <div class="pitch-divider">VS</div>
    <div class="pitch-col">
      <h2 class="pitch-label">// WITH FINCH</h2>
      <ul class="pitch-list good">
        <li>Fully offline after first model download</li>
        <li>Zero marginal cost per query</li>
        <li>Code stays on your machine</li>
        <li>6 model families, pick what fits your hardware</li>
        <li>Useful from day one (pre-trained models)</li>
      </ul>
    </div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     FEATURES
═══════════════════════════════════════════ -->
<section id="features">
  <h2 class="sec-title">// FEATURES</h2>
  <div class="cards">

    <div class="card">
      <div class="card-glyph">▣</div>
      <h3>WORKS OFFLINE</h3>
      <p>6 model families via ONNX Runtime — Qwen, Llama, Gemma, Mistral, Phi, DeepSeek. Zero latency. No subscriptions or rate limits.</p>
    </div>

    <div class="card">
      <div class="card-glyph">◈</div>
      <h3>ANE ACCELERATION</h3>
      <p>Apple Neural Engine via CoreML on Apple Silicon (M1–M4). Linux supports CUDA, ROCm, and CPU via ONNX Runtime execution providers. Auto-selected based on your hardware.</p>
    </div>

    <div class="card">
      <div class="card-glyph">◉</div>
      <h3>PRIVACY FIRST</h3>
      <p>Your code never leaves your machine. No telemetry. Everything runs locally — your proprietary code stays yours.</p>
    </div>

    <div class="card">
      <div class="card-glyph">▶</div>
      <h3>INSTANT STARTUP</h3>
      <p>REPL appears in under 100ms. Model loads in the background. While it's loading on first run, optionally falls back to a cloud provider.</p>
    </div>

    <div class="card">
      <div class="card-glyph">◆</div>
      <h3>AGENTIC TOOLS</h3>
      <p>Read, Glob, Grep, Bash, WebFetch. Full multi-turn agentic loop with permission system. Like Claude Code, but entirely local.</p>
    </div>

    <div class="card">
      <div class="card-glyph">◇</div>
      <h3>LORA FINE-TUNING</h3>
      <p>Weighted feedback collection infrastructure is in place. LoRA adapter training and loading is the next major milestone — contributions welcome.</p>
    </div>

  </div>
</section>

<!-- ═══════════════════════════════════════════
     HOW IT WORKS
═══════════════════════════════════════════ -->
<section id="how-it-works">
  <h2 class="sec-title">// HOW IT WORKS</h2>
  <div class="flow-wrap">
<pre class="flow-art">
  ┌──────────────────────────────────────────────────────┐
  │                     YOUR REQUEST                      │
  └──────────────────────┬───────────────────────────────┘
                         │
                         ▼
               ┌──────────────────┐
               │   MODEL READY?   │
               └──┬───────────────┘
                 NO                YES
                  │                 │
                  ▼                 ▼
        ┌──────────────┐  ┌──────────────────────────────┐
        │ TEACHER API   │  │   LOCAL MODEL (ONNX)          │
        │ Claude/GPT-4  │  │  Qwen · Llama · Gemma · Phi   │
        │ Gemini/Grok   │  │  Mistral · DeepSeek           │
        │ (while loading│  │  ANE via CoreML · &lt;100ms      │
        │  first time)  │  └────────────┬─────────────────┘
        └──────────────┘               │
                                        ▼
                              ┌──────────────────┐
                              │     RESPONSE      │
                              └──────────────────┘
</pre>
  </div>

  <div class="steps-grid">
    <div class="step">
      <span class="step-n">01</span>
      <div>
        <h3>INSTALL &amp; RUN</h3>
        <p>One curl command installs the binary. The REPL starts in under 100ms. On first run, Finch downloads a Qwen model in the background — you can start asking questions immediately.</p>
      </div>
    </div>
    <div class="step">
      <span class="step-n">02</span>
      <div>
        <h3>QUERY LOCALLY</h3>
        <p>Queries run on your local ONNX model. Apple Silicon uses the ANE via CoreML automatically. Linux supports CUDA and other ONNX Runtime execution providers. No internet required after the model is cached.</p>
      </div>
    </div>
    <div class="step">
      <span class="step-n">03</span>
      <div>
        <h3>USE AGENTIC TOOLS</h3>
        <p>Finch can read files, search your codebase, run shell commands, and fetch web pages — all with your approval. Full multi-turn agentic loop, just like Claude Code.</p>
      </div>
    </div>
    <div class="step">
      <span class="step-n">04</span>
      <div>
        <h3>LORA COMING SOON</h3>
        <p>Feedback collection infrastructure is ready (<code>Ctrl+G</code> / <code>Ctrl+B</code>). LoRA fine-tuning to adapt the model to your codebase is the next major milestone.</p>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     SYSTEM REQUIREMENTS
═══════════════════════════════════════════ -->
<section id="models">
  <h2 class="sec-title">// SUPPORTED MODELS</h2>
  <div class="table-wrap">
    <table class="model-table">
      <thead>
        <tr>
          <th>FAMILY</th>
          <th>SIZES</th>
          <th>FORMAT</th>
          <th>NOTES</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Qwen 2.5</td>
          <td>1.5B · 3B · 7B · 14B</td>
          <td>ONNX</td>
          <td class="bar">Recommended · auto-selected by RAM</td>
        </tr>
        <tr>
          <td>Llama 3</td>
          <td>3B · 8B · 70B</td>
          <td>ONNX</td>
          <td class="bar">Meta · general purpose</td>
        </tr>
        <tr>
          <td>Gemma 2</td>
          <td>2B · 9B · 27B</td>
          <td>ONNX</td>
          <td class="bar">Google · strong reasoning</td>
        </tr>
        <tr>
          <td>Mistral</td>
          <td>7B · 22B</td>
          <td>ONNX</td>
          <td class="bar">Mistral AI · efficient</td>
        </tr>
        <tr>
          <td>Phi</td>
          <td>2B · 3.8B · 14B</td>
          <td>ONNX</td>
          <td class="bar">Microsoft · small + capable</td>
        </tr>
        <tr>
          <td>DeepSeek Coder</td>
          <td>1.3B · 6.7B · 16B · 33B</td>
          <td>ONNX</td>
          <td class="bar">Optimised for code</td>
        </tr>
      </tbody>
    </table>
  </div>
  <p class="table-note">ANE via CoreML on Apple Silicon (M1–M4) · CUDA/ROCm/CPU on Linux via ONNX Runtime execution providers · Qwen auto-selected by RAM by default</p>
</section>

<!-- ═══════════════════════════════════════════
     INSTALL
═══════════════════════════════════════════ -->
<section id="install">
  <h2 class="sec-title">// INSTALL</h2>

  <div class="install-box">
    <div class="install-cmd">
      <span class="prompt">$</span>
      <code id="install-text">curl -sSL https://raw.githubusercontent.com/darwin-finch/finch/main/install.sh | sh</code>
      <button class="copy-btn" id="copy-btn" onclick="copyInstall()">COPY</button>
    </div>
    <p class="install-meta">
      macOS Apple Silicon · Linux x86_64 · MIT License ·
      <a href="https://github.com/darwin-finch/finch/blob/main/install.sh" target="_blank" rel="noopener">view script ↗</a>
    </p>
  </div>

  <ol class="install-steps">
    <li>
      <span class="step-n">01</span>
      <div><strong>Installs the binary</strong> to <code>~/.local/bin/finch</code> and adds it to your PATH</div>
    </li>
    <li>
      <span class="step-n">02</span>
      <div>Run <code>finch</code> — the REPL starts in under 100ms</div>
    </li>
    <li>
      <span class="step-n">03</span>
      <div>Run <code>finch setup</code> to configure an optional teacher API key (Claude, GPT-4, etc.)</div>
    </li>
    <li>
      <span class="step-n">04</span>
      <div>On first run, Finch downloads a local model in the background — start querying immediately</div>
    </li>
  </ol>

  <div class="build-from-source">
    <span class="dim">// or build from source</span>
    <div class="install-cmd secondary">
      <span class="prompt">$</span>
      <code>git clone https://github.com/darwin-finch/finch &amp;&amp; cd finch &amp;&amp; cargo build --release</code>
    </div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     CONTRIBUTE
═══════════════════════════════════════════ -->
<section id="contribute">
  <h2 class="sec-title">// CONTRIBUTE</h2>
  <p class="contrib-intro">Finch is early-stage and actively looking for contributors. All issues are tracked on GitHub.</p>

  <div class="contrib-cards">
    <a class="contrib-card" href="https://github.com/darwin-finch/finch/issues?q=label%3A%22good+first+issue%22" target="_blank" rel="noopener">
      <span class="issue-tag good-first">good first issue</span>
      <h3>Good First Issues</h3>
      <p>Browse issues tagged as good first issues — a quick way to get familiar with a Rust codebase that covers ONNX, TUI, async, and tool execution.</p>
    </a>
    <a class="contrib-card" href="https://github.com/darwin-finch/finch/issues?q=label%3A%22help+wanted%22" target="_blank" rel="noopener">
      <span class="issue-tag help-wanted">help wanted</span>
      <h3>Help Wanted</h3>
      <p>Integration tests, model adapter improvements, multi-provider routing, and more. Check GitHub Issues for the current list.</p>
    </a>
    <a class="contrib-card" href="https://github.com/darwin-finch/finch/issues" target="_blank" rel="noopener">
      <span class="issue-tag complex">big ticket</span>
      <h3>LoRA Adapter Loading</h3>
      <p>Load fine-tuned LoRA adapters into ONNX Runtime at inference time. The largest open milestone — would unlock continuous local learning.</p>
    </a>
  </div>

  <p class="contrib-footer">
    Built with Rust · PRs welcome ·
    <a href="https://github.com/darwin-finch/finch">github.com/darwin-finch/finch</a>
  </p>
</section>

<!-- ═══════════════════════════════════════════
     FOOTER
═══════════════════════════════════════════ -->
<footer id="footer">
  <pre class="footer-bird">      ▄▄▄▄▄▄
    ▗▟█●██▙►  finch — local AI coding assistant
  ▐████████▌  MIT License
  ▝▜██████▛▘  darwin-finch/finch
     ╥  ╥
    ╱    ╲</pre>

  <nav class="footer-links">
    <a href="https://github.com/darwin-finch/finch">GitHub</a>
    <a href="https://github.com/darwin-finch/finch/releases">Releases</a>
    <a href="https://github.com/darwin-finch/finch/issues">Issues</a>
    <a href="docs.html">Docs</a>
    <a href="https://github.com/darwin-finch/finch/blob/main/CHANGELOG.md">Changelog</a>
    <a href="https://github.com/darwin-finch/finch/blob/main/README.md">README</a>
  </nav>
  <p class="footer-copy">Runs locally. No cloud. No telemetry. Just code.</p>
</footer>

<script src="app.js"></script>
</body>
</html>
