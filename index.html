<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Finch — Local AI Coding Assistant</title>
  <meta name="description" content="Open-source AI coding assistant that runs entirely on your machine. Offline. Private. 6 model families. Apple Neural Engine acceleration. Built in Rust.">
  <meta property="og:title" content="Finch — Local AI Coding Assistant">
  <meta property="og:description" content="Offline. Private. 6 model families. ANE acceleration on Apple Silicon. Built in Rust.">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://darwin-finch.github.io">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Finch — Local AI Coding Assistant">
  <meta name="twitter:description" content="Offline. Private. 6 model families. ANE acceleration on Apple Silicon. Built in Rust.">
  <link rel="icon" href="favicon.svg" type="image/svg+xml">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;700&display=swap">
  <link rel="stylesheet" href="style.css">
</head>
<body>

<!-- CRT scanline overlay -->
<div class="crt" aria-hidden="true"></div>

<!-- ═══════════════════════════════════════════
     NAV
═══════════════════════════════════════════ -->
<nav id="nav">
  <a href="/" class="nav-logo">FINCH</a>
  <button class="nav-toggle" onclick="toggleNav()" aria-label="Menu">☰</button>
  <div class="nav-links" id="nav-links">
    <a href="#open-agent">WHY&nbsp;FINCH</a>
    <a href="#usage">USAGE</a>
    <a href="#features">FEATURES</a>
    <a href="#how-it-works">HOW&nbsp;IT&nbsp;WORKS</a>
    <a href="#install">INSTALL</a>
    <a href="docs.html">DOCS</a>
    <a href="#sponsor">SPONSOR</a>
    <a href="https://github.com/darwin-finch/finch" target="_blank" rel="noopener">GITHUB</a>
  </div>
</nav>

<!-- ═══════════════════════════════════════════
     HERO
═══════════════════════════════════════════ -->
<section id="hero">
  <div class="hero-inner">

    <pre class="logo-art" aria-label="FINCH">██████╗ ██╗███╗   ██╗ ██████╗██╗  ██╗
██╔════╝██║████╗  ██║██╔════╝██║  ██║
█████╗  ██║██╔██╗ ██║██║     ███████║
██╔══╝  ██║██║╚██╗██║██║     ██╔══██║
██║     ██║██║ ╚████║╚██████╗██║  ██║
╚═╝     ╚═╝╚═╝  ╚═══╝ ╚═════╝╚═╝  ╚═╝</pre>

    <p class="hero-sub">AI coding assistant · runs on your machine · works offline · learns your style</p>

    <div class="badges">
      <span>WRITTEN IN RUST</span>
      <span>SINGLE BINARY</span>
      <span>WORKS OFFLINE</span>
      <span>PRIVATE BY DEFAULT</span>
      <span>OPEN SOURCE</span>
    </div>

    <!-- Animated terminal -->
    <div class="terminal" id="terminal">
      <div class="term-bar">
        <span class="dot dot-r"></span>
        <span class="dot dot-y"></span>
        <span class="dot dot-g"></span>
        <span class="term-title">zsh — finch — 80×24</span>
      </div>
      <div class="term-body">
        <div id="term-out"></div>
        <span class="term-cursor">▋</span>
      </div>
    </div>

    <div class="hero-ctas">
      <a href="#install" class="btn-primary">INSTALL NOW</a>
      <a href="https://github.com/darwin-finch/finch" class="btn-ghost" target="_blank" rel="noopener">★ VIEW ON GITHUB</a>
    </div>

  </div>
</section>

<!-- ═══════════════════════════════════════════
     THE PITCH
═══════════════════════════════════════════ -->
<section id="pitch">
  <div class="pitch-inner">
    <div class="pitch-col">
      <h2 class="pitch-label">// THE PROBLEM</h2>
      <ul class="pitch-list bad">
        <li>Constant internet connection required</li>
        <li>Every query costs API money</li>
        <li>Your code goes to the cloud</li>
        <li>No learning from your patterns</li>
        <li>Ongoing API costs for every single query</li>
      </ul>
    </div>
    <div class="pitch-divider">VS</div>
    <div class="pitch-col">
      <h2 class="pitch-label">// WITH FINCH</h2>
      <ul class="pitch-list good">
        <li>Fully offline after first model download</li>
        <li>Zero marginal cost per query</li>
        <li>Code stays on your machine</li>
        <li>6 model families, pick what fits your hardware</li>
        <li>Useful from day one (pre-trained models)</li>
      </ul>
    </div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     THE OPEN AGENT
═══════════════════════════════════════════ -->
<section id="open-agent">
  <h2 class="sec-title">// THE OPEN AGENT</h2>

  <div class="agent-headline">
    <p class="agent-lede">Claude Code is great — if you're on Claude.<br>
    Finch brings the same agentic experience to <strong>any</strong> provider.</p>
    <div class="provider-row">
      <span>Grok</span><span>GPT-4o</span><span>Gemini</span><span>Mistral</span><span>Groq</span><span>Claude</span><span>Local&nbsp;ONNX</span>
    </div>
  </div>

  <div class="agent-grid">

    <div class="agent-card agent-wide">
      <div class="agent-icon">⬡</div>
      <div>
        <h3>FULL TOOL USE ON ANY LLM</h3>
        <p>Read, Glob, Grep, Bash, WebFetch — the complete agentic tool loop works with every supported provider. Grok users, GPT-4 users, Mistral users all get the same multi-turn, permission-gated, streaming agent. Switch mid-session with <code>/teacher grok</code>.</p>
      </div>
    </div>

    <div class="agent-card">
      <div class="agent-icon">▤</div>
      <h3>CLAUDE.MD + FINCH.MD</h3>
      <p>Auto-loads project instructions by walking the filesystem from root to your working directory — exactly like Claude Code. <code>FINCH.md</code> is a vendor-neutral alias: one instruction file that works with Finch, Claude Code, Cursor, or any assistant that respects it.</p>
    </div>

    <div class="agent-card">
      <div class="agent-icon">◫</div>
      <h3>MEMTREE MEMORY</h3>
      <p>Persistent hierarchical memory tree, not RAG. Structured context accumulates across sessions and is injected into every conversation. No embedding models. No vector databases. No chunking artefacts.</p>
    </div>

    <div class="agent-card">
      <div class="agent-icon">⬡</div>
      <h3>MCP PLUGINS</h3>
      <p>Extend with any Model Context Protocol server — the same ecosystem as Claude Desktop and VS Code. Connect databases, IDEs, APIs, or custom internal tools with a single config entry.</p>
    </div>

    <div class="agent-card">
      <div class="agent-icon">▶</div>
      <h3>AUTONOMOUS MODE <span class="tag-macos">macOS</span></h3>
      <p>macOS Accessibility API + auto-accept edits = unsupervised agent mode. Finch can navigate apps, apply diffs, and execute multi-step workflows without a confirmation prompt at every step.</p>
    </div>

  </div>
</section>

<!-- ═══════════════════════════════════════════
     USE IT YOUR WAY
═══════════════════════════════════════════ -->
<section id="usage">
  <h2 class="sec-title">// USE IT YOUR WAY</h2>

  <div class="use-grid">

    <div class="use-card">
      <div class="use-num">01</div>
      <h3>INTERACTIVE REPL</h3>
      <p>Full TUI with scrollback, streaming, plan mode, and agentic tool use. Ghost text autocomplete. Session history.</p>
      <pre class="use-code"><span class="uc-prompt">$</span> finch

      ▄▄▄▄▄▄
    ▗▟█●██▙►  finch v0.5.2
  ▐████████▌  Qwen-2.5-7B · ready
  ▝▜██████▛▘  ~/repos/myproject
     ╥  ╥
    ╱    ╲

<span class="uc-dim">&gt;</span> How do I use lifetimes in Rust?<span class="uc-cursor">▋</span></pre>
    </div>

    <div class="use-card">
      <div class="use-num">02</div>
      <h3>SINGLE QUERY + PIPE</h3>
      <p>Scriptable one-shot queries. Pipe stdin directly into finch. Works great in shell scripts, CI, and editor integrations.</p>
      <pre class="use-code"><span class="uc-prompt">$</span> finch query <span class="uc-str">"What is a Rust lifetime?"</span>

<span class="uc-prompt">$</span> echo <span class="uc-str">"Explain this error"</span> | finch

<span class="uc-prompt">$</span> cat error.log | finch <span class="uc-str">"what went wrong?"</span>

<span class="uc-prompt">$</span> git diff | finch <span class="uc-str">"write a commit message"</span></pre>
    </div>

    <div class="use-card use-full">
      <div class="use-num">03</div>
      <h3>BACKGROUND DAEMON — LOCAL MODEL AS A SERVICE</h3>
      <p>Finch spawns a background daemon automatically. It exposes an <strong>OpenAI-compatible API</strong> on port 11435 — so VS Code extensions, scripts, and any tool that speaks the OpenAI protocol can use your local model with zero cloud costs.</p>
      <p>Enable <strong>mDNS/Bonjour</strong> advertising and every machine on your local network can discover and use the model running on your desktop — no manual IP configuration, no cloud, no API keys.</p>
      <div class="use-code-row">
        <pre class="use-code"><span class="uc-dim"># Start daemon with network sharing</span>
<span class="uc-prompt">$</span> finch daemon --bind 0.0.0.0:11435 --mdns

  Listening on  0.0.0.0:11435
  mDNS name     finch.local
  Model         Qwen-2.5-7B [ANE]
  API           OpenAI-compatible

<span class="uc-dim"># Other machines on LAN connect to:</span>
<span class="uc-dim"># http://finch.local:11435</span></pre>
        <pre class="use-code"><span class="uc-dim">// VS Code — Continue.dev config</span>
{
  <span class="uc-str">"models"</span>: [{
    <span class="uc-str">"title"</span>: <span class="uc-str">"Finch (local)"</span>,
    <span class="uc-str">"provider"</span>: <span class="uc-str">"openai"</span>,
    <span class="uc-str">"model"</span>: <span class="uc-str">"local"</span>,
    <span class="uc-str">"apiBase"</span>:
      <span class="uc-str">"http://localhost:11435"</span>,
    <span class="uc-str">"apiKey"</span>: <span class="uc-str">"none"</span>
  }]
}</pre>
      </div>
    </div>

  </div>
</section>

<!-- ═══════════════════════════════════════════
     FEATURES
═══════════════════════════════════════════ -->
<section id="features">
  <h2 class="sec-title">// FEATURES</h2>
  <div class="cards">

    <div class="card">
      <div class="card-glyph">▣</div>
      <h3>WORKS OFFLINE</h3>
      <p>6 model families via ONNX Runtime — Qwen, Llama, Gemma, Mistral, Phi, DeepSeek. Candle backend available on Linux. Zero latency. No subscriptions or rate limits.</p>
    </div>

    <div class="card">
      <div class="card-glyph">◈</div>
      <h3>ANE ACCELERATION</h3>
      <p>Apple Neural Engine via CoreML on Apple Silicon (M1–M4). Linux supports CUDA, ROCm, CPU via ONNX, or the Candle backend. ONNX is primary; Candle + Metal on macOS is unreliable so ONNX + CoreML is used there instead.</p>
    </div>

    <div class="card">
      <div class="card-glyph">◉</div>
      <h3>PRIVACY FIRST</h3>
      <p>Your code never leaves your machine. No telemetry. Everything runs locally — your proprietary code stays yours.</p>
    </div>

    <div class="card">
      <div class="card-glyph">▶</div>
      <h3>INSTANT STARTUP</h3>
      <p>REPL appears in under 100ms. Model loads in the background. While it's loading on first run, optionally falls back to a cloud provider.</p>
    </div>

    <div class="card">
      <div class="card-glyph">◆</div>
      <h3>AGENTIC TOOLS</h3>
      <p>Read, Glob, Grep, Bash, WebFetch. Full multi-turn agentic loop with permission system. Like Claude Code, but entirely local.</p>
    </div>

    <div class="card">
      <div class="card-glyph">◇</div>
      <h3>LORA FINE-TUNING</h3>
      <p>Weighted feedback collection infrastructure is in place. LoRA adapter training and loading is the next major milestone — contributions welcome.</p>
    </div>

  </div>
</section>

<!-- ═══════════════════════════════════════════
     HOW IT WORKS
═══════════════════════════════════════════ -->
<section id="how-it-works">
  <h2 class="sec-title">// HOW IT WORKS</h2>
  <div class="flow-wrap">
<pre class="flow-art">
  ┌──────────────────────────────────────────────────────┐
  │                     YOUR REQUEST                      │
  └──────────────────────┬───────────────────────────────┘
                         │
                         ▼
               ┌──────────────────┐
               │   MODEL READY?   │
               └──┬───────────────┘
                 NO                YES
                  │                 │
                  ▼                 ▼
        ┌──────────────┐  ┌──────────────────────────────┐
        │ TEACHER API   │  │   LOCAL MODEL (ONNX)          │
        │ Claude/GPT-4  │  │  Qwen · Llama · Gemma · Phi   │
        │ Gemini/Grok   │  │  Mistral · DeepSeek           │
        │ (while loading│  │  ANE via CoreML · &lt;100ms      │
        │  first time)  │  └────────────┬─────────────────┘
        └──────────────┘               │
                                        ▼
                              ┌──────────────────┐
                              │     RESPONSE      │
                              └──────────────────┘
</pre>
  </div>

  <div class="steps-grid">
    <div class="step">
      <span class="step-n">01</span>
      <div>
        <h3>INSTALL &amp; RUN</h3>
        <p>One curl command installs the binary. The REPL starts in under 100ms. On first run, Finch downloads a Qwen model in the background — you can start asking questions immediately.</p>
      </div>
    </div>
    <div class="step">
      <span class="step-n">02</span>
      <div>
        <h3>QUERY LOCALLY</h3>
        <p>Queries run on your local ONNX model. Apple Silicon uses the ANE via CoreML automatically. Linux supports CUDA and other ONNX Runtime execution providers. No internet required after the model is cached.</p>
      </div>
    </div>
    <div class="step">
      <span class="step-n">03</span>
      <div>
        <h3>USE AGENTIC TOOLS</h3>
        <p>Finch can read files, search your codebase, run shell commands, and fetch web pages — all with your approval. Full multi-turn agentic loop, just like Claude Code.</p>
      </div>
    </div>
    <div class="step">
      <span class="step-n">04</span>
      <div>
        <h3>LORA COMING SOON</h3>
        <p>Feedback collection infrastructure is ready (<code>Ctrl+G</code> / <code>Ctrl+B</code>). LoRA fine-tuning to adapt the model to your codebase is the next major milestone.</p>
      </div>
    </div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     SYSTEM REQUIREMENTS
═══════════════════════════════════════════ -->
<section id="models">
  <h2 class="sec-title">// SUPPORTED MODELS</h2>
  <div class="table-wrap">
    <table class="model-table">
      <thead>
        <tr>
          <th>FAMILY</th>
          <th>SIZES</th>
          <th>FORMAT</th>
          <th>NOTES</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Qwen 2.5</td>
          <td>1.5B · 3B · 7B · 14B</td>
          <td>ONNX</td>
          <td class="bar">Recommended · auto-selected by RAM</td>
        </tr>
        <tr>
          <td>Llama 3</td>
          <td>3B · 8B · 70B</td>
          <td>ONNX</td>
          <td class="bar">Meta · general purpose</td>
        </tr>
        <tr>
          <td>Gemma 2</td>
          <td>2B · 9B · 27B</td>
          <td>ONNX</td>
          <td class="bar">Google · strong reasoning</td>
        </tr>
        <tr>
          <td>Mistral</td>
          <td>7B · 22B</td>
          <td>ONNX</td>
          <td class="bar">Mistral AI · efficient</td>
        </tr>
        <tr>
          <td>Phi</td>
          <td>2B · 3.8B · 14B</td>
          <td>ONNX</td>
          <td class="bar">Microsoft · small + capable</td>
        </tr>
        <tr>
          <td>DeepSeek Coder</td>
          <td>1.3B · 6.7B · 16B · 33B</td>
          <td>ONNX</td>
          <td class="bar">Optimised for code</td>
        </tr>
      </tbody>
    </table>
  </div>
  <p class="table-note">ANE via CoreML on Apple Silicon (M1–M4) · CUDA/ROCm/CPU on Linux via ONNX Runtime execution providers · Qwen auto-selected by RAM by default</p>
</section>

<!-- ═══════════════════════════════════════════
     INSTALL
═══════════════════════════════════════════ -->
<section id="install">
  <h2 class="sec-title">// INSTALL</h2>

  <div class="install-box">
    <div class="install-cmd">
      <span class="prompt">$</span>
      <code id="install-text">curl -sSL https://raw.githubusercontent.com/darwin-finch/finch/main/install.sh | sh</code>
      <button class="copy-btn" id="copy-btn" onclick="copyInstall()">COPY</button>
    </div>
    <p class="install-meta">
      macOS Apple Silicon · Linux x86_64 · MIT License ·
      <a href="https://github.com/darwin-finch/finch/blob/main/install.sh" target="_blank" rel="noopener">view script ↗</a>
    </p>
    <p class="install-note">One self-contained binary — no Node, no Python, no Docker, no runtime dependencies.</p>
  </div>

  <ol class="install-steps">
    <li>
      <span class="step-n">01</span>
      <div><strong>Installs the binary</strong> to <code>~/.local/bin/finch</code> and adds it to your PATH</div>
    </li>
    <li>
      <span class="step-n">02</span>
      <div>Run <code>finch</code> — the REPL starts in under 100ms</div>
    </li>
    <li>
      <span class="step-n">03</span>
      <div>Run <code>finch setup</code> to configure an optional teacher API key (Claude, GPT-4, etc.)</div>
    </li>
    <li>
      <span class="step-n">04</span>
      <div>On first run, Finch downloads a local model in the background — start querying immediately</div>
    </li>
  </ol>

  <div class="build-from-source">
    <span class="dim">// or build from source</span>
    <div class="install-cmd secondary">
      <span class="prompt">$</span>
      <code>git clone https://github.com/darwin-finch/finch &amp;&amp; cd finch &amp;&amp; cargo build --release</code>
    </div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     CONTRIBUTE
═══════════════════════════════════════════ -->
<section id="contribute">
  <h2 class="sec-title">// CONTRIBUTE</h2>
  <p class="contrib-intro">Finch is early-stage and actively looking for contributors. All issues are tracked on GitHub.</p>

  <div class="contrib-cards">
    <a class="contrib-card" href="https://github.com/darwin-finch/finch/issues?q=label%3A%22good+first+issue%22" target="_blank" rel="noopener">
      <span class="issue-tag good-first">good first issue</span>
      <h3>Good First Issues</h3>
      <p>Browse issues tagged as good first issues — a quick way to get familiar with a Rust codebase that covers ONNX, TUI, async, and tool execution.</p>
    </a>
    <a class="contrib-card" href="https://github.com/darwin-finch/finch/issues?q=label%3A%22help+wanted%22" target="_blank" rel="noopener">
      <span class="issue-tag help-wanted">help wanted</span>
      <h3>Help Wanted</h3>
      <p>Integration tests, model adapter improvements, multi-provider routing, and more. Check GitHub Issues for the current list.</p>
    </a>
    <a class="contrib-card" href="https://github.com/darwin-finch/finch/issues" target="_blank" rel="noopener">
      <span class="issue-tag complex">big ticket</span>
      <h3>LoRA Adapter Loading</h3>
      <p>Load fine-tuned LoRA adapters into ONNX Runtime at inference time. The largest open milestone — would unlock continuous local learning.</p>
    </a>
  </div>

  <p class="contrib-footer">
    Built with Rust · PRs welcome ·
    <a href="https://github.com/darwin-finch/finch">github.com/darwin-finch/finch</a>
  </p>
</section>

<!-- ═══════════════════════════════════════════
     SPONSOR
═══════════════════════════════════════════ -->
<section id="sponsor">
  <h2 class="sec-title">// SUPPORT THE PROJECT</h2>
  <p class="sponsor-lede">Finch is free and open-source. Sponsorships help cover API costs and fund the big open milestones.</p>

  <div class="sponsor-tiers">

    <a class="sponsor-tier" href="https://github.com/sponsors/darwin-finch" target="_blank" rel="noopener">
      <div class="tier-amount">$5 <span>/mo</span></div>
      <div class="tier-name">SUPPORTER</div>
      <div class="tier-desc">Sponsor badge on your GitHub profile. Every bit helps.</div>
    </a>

    <a class="sponsor-tier" href="https://github.com/sponsors/darwin-finch" target="_blank" rel="noopener">
      <div class="tier-amount">$25 <span>/mo</span></div>
      <div class="tier-name">BACKER</div>
      <div class="tier-desc">Your name or logo in the project README.</div>
    </a>

    <a class="sponsor-tier tier-highlight" href="https://github.com/sponsors/darwin-finch" target="_blank" rel="noopener">
      <div class="tier-amount">$100 <span>/mo</span></div>
      <div class="tier-name">SPONSOR</div>
      <div class="tier-desc">Your name or logo on this website. Bug reports prioritized.</div>
    </a>

    <a class="sponsor-tier" href="https://github.com/sponsors/darwin-finch" target="_blank" rel="noopener">
      <div class="tier-amount">$200 <span>one-time</span></div>
      <div class="tier-name">PAIR SESSION</div>
      <div class="tier-desc">One hour pair-programming. Open an issue after sponsoring.</div>
    </a>

    <a class="sponsor-tier" href="https://github.com/sponsors/darwin-finch" target="_blank" rel="noopener">
      <div class="tier-amount">$5k <span>one-time</span></div>
      <div class="tier-name">CONTRACT</div>
      <div class="tier-desc">Large project or contract work. Get in touch via GitHub issues.</div>
    </a>

  </div>

  <a href="https://github.com/sponsors/darwin-finch" class="btn-sponsor" target="_blank" rel="noopener">♥ SPONSOR ON GITHUB</a>
</section>

<!-- ═══════════════════════════════════════════
     FOOTER
═══════════════════════════════════════════ -->
<footer id="footer">
  <pre class="footer-bird">      ▄▄▄▄▄▄
    ▗▟█●██▙►  finch — local AI coding assistant
  ▐████████▌  MIT License
  ▝▜██████▛▘  darwin-finch/finch
     ╥  ╥
    ╱    ╲</pre>

  <nav class="footer-links">
    <a href="https://github.com/darwin-finch/finch">GitHub</a>
    <a href="https://github.com/darwin-finch/finch/releases">Releases</a>
    <a href="https://github.com/darwin-finch/finch/issues">Issues</a>
    <a href="docs.html">Docs</a>
    <a href="https://github.com/darwin-finch/finch/blob/main/CHANGELOG.md">Changelog</a>
    <a href="https://github.com/darwin-finch/finch/blob/main/README.md">README</a>
  </nav>
  <div class="footer-support">
    <span class="footer-support-label">SUPPORT THE PROJECT</span>
    <a href="https://github.com/sponsors/darwin-finch" target="_blank" rel="noopener" class="footer-support-link">♥ GitHub Sponsors</a>
    <span class="footer-divider">·</span>
    <span class="footer-support-note">Available for consulting &amp; contracts —
      <a href="https://github.com/darwin-finch/finch/issues" target="_blank" rel="noopener">open an issue</a> or reach out via GitHub
    </span>
  </div>
  <p class="footer-copy">Runs locally. No cloud. No telemetry. Just code.</p>
</footer>

<script src="app.js"></script>
</body>
</html>
